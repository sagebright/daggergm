# PHASE 3: Workflow Validation & Testing

**Execution Command**: `/execute-feature documentation/PHASE_3_workflow_validation.md`

---

## ðŸ“‹ Overview

Validate the new GitHub Actions workflow and MCP server integrations through comprehensive testing.

**Goals**:

- Verify workflow runs correctly with all scenarios
- Validate MCP integrations work end-to-end
- Confirm performance improvements achieved
- Document any issues and resolutions
- Create monitoring dashboard

**Estimated Time**: 30-45 minutes
**Prerequisites**: Phase 1 and Phase 2 completed

---

## ðŸŽ¯ Success Criteria

- [ ] Documentation-only changes skip CI (0 min)
- [ ] Full test suite completes in ~20 minutes
- [ ] Coverage threshold enforced (90%)
- [ ] Flaky tests auto-retry successfully
- [ ] Deployment triggers only on main
- [ ] MCP servers respond to all test commands
- [ ] Can monitor workflow via GitHub MCP
- [ ] Can query database via Supabase MCP

---

## ðŸ“ Tasks

### Task 1: Validate Workflow Syntax

**Before testing, ensure workflow is valid**:

```bash
# Install workflow validation tool
brew install actionlint  # macOS
# OR
curl -L https://github.com/rhysd/actionlint/releases/latest/download/actionlint_linux_amd64.tar.gz | tar xz
sudo mv actionlint /usr/local/bin/

# Validate workflow syntax
actionlint .github/workflows/ci.yml

# Expected: No errors
# If errors, fix before continuing
```

**Alternative validation** (using GitHub API):

```bash
# Check if workflow is recognized by GitHub
gh workflow list

# Expected: Should show "CI/CD Pipeline"
```

---

### Task 2: Test Scenario 1 - Documentation-Only Changes

**Goal**: Verify documentation changes skip CI entirely

```bash
# Make a documentation-only change
echo "## Testing CI Skip" >> README.md
git add README.md
git commit -m "docs: test documentation skip"
git push origin main
```

**Validation using MCP**:

```
Ask Claude:
"Show me the latest GitHub Actions run for daggergm"

Expected: No new run triggered, or run was skipped
Time: 0 minutes (instant)
```

**Validation using CLI** (if MCP not working):

```bash
gh run list --limit 1

# Expected: Either no new run, or status shows "skipped"
```

**âœ… Success Criteria**:

- No workflow run triggered, OR
- Workflow run shows "skipped" status
- Takes < 10 seconds

---

### Task 3: Test Scenario 2 - Manual Skip with [skip ci]

**Goal**: Verify `[skip ci]` flag works

```bash
# Make a code change with [skip ci]
echo "// test skip ci" >> app/page.tsx
git add app/page.tsx
git commit -m "test: verify [skip ci] works [skip ci]"
git push origin main
```

**Validation using MCP**:

```
Ask Claude:
"What's the status of the latest CI run? Was it skipped?"

Expected: Run was skipped or not triggered
```

**Validation using CLI**:

```bash
gh run list --limit 1

# Expected: No new run, or status "skipped"
```

**âœ… Success Criteria**:

- Workflow skipped despite code change
- `[skip ci]` flag respected

---

### Task 4: Test Scenario 3 - Lint-Only Changes

**Goal**: Verify lint-only changes are fast

```bash
# Make a formatting change
npx prettier --write app/page.tsx
git add app/page.tsx
git commit -m "style: format page.tsx"
git push origin main
```

**Monitor using MCP**:

```
Ask Claude:
"Watch the current GitHub Actions run and tell me when it completes"

Expected: Should complete in ~5 minutes (only lint/typecheck)
```

**Monitor using CLI**:

```bash
gh run watch

# Expected:
# - lint-and-typecheck: ~3-5 min âœ…
# - test-unit: skipped (no code changes)
# - test-e2e: skipped (no code changes)
# - build: runs (required)
# Total: ~7-8 minutes
```

**âœ… Success Criteria**:

- Completes in < 10 minutes
- Only lint, typecheck, and build run
- Tests skipped (no logic changes)

---

### Task 5: Test Scenario 4 - Full Test Suite

**Goal**: Verify complete workflow with all jobs

```bash
# Make a meaningful code change
cat >> app/page.tsx << 'EOF'

// Test full CI pipeline
export const metadata = {
  description: 'Testing CI/CD pipeline',
};
EOF

git add app/page.tsx
git commit -m "feat: test full CI pipeline"
git push origin main
```

**Monitor using MCP**:

```
Ask Claude:
"Monitor the GitHub Actions run and give me a summary when complete"

Expected: Claude watches run and reports status
```

**Monitor using CLI**:

```bash
# Watch in real-time
gh run watch

# Or check status periodically
watch -n 10 "gh run view --log-failed"
```

**âœ… Success Criteria**:

- All jobs run: lint-and-typecheck, test-unit, test-e2e, build
- test-unit includes auto-retry (`--retry=2`)
- Coverage enforced (90% threshold)
- E2E tests run in parallel
- Total time: ~20-25 minutes
- All jobs pass

---

### Task 6: Verify Auto-Retry Logic

**Goal**: Ensure flaky tests retry automatically

**Check test output**:

```bash
# View detailed logs from latest run
gh run view --log

# Search for retry indicators
gh run view --log | grep -i "retry"

# Expected: Should see retry messages if any test was flaky
```

**Using MCP**:

```
Ask Claude:
"Show me the test logs from the latest run. Were any tests retried?"

Expected: Claude shows if any tests needed retries
```

**âœ… Success Criteria**:

- If test fails first time, automatically retries
- Test marked as passed if succeeds on retry
- Logs show retry attempts

---

### Task 7: Test Coverage Enforcement

**Goal**: Verify 90% coverage threshold is enforced

**Temporary test** (will fail intentionally):

```bash
# Temporarily lower coverage threshold to test enforcement
sed -i '' 's/COVERAGE < 90/COVERAGE < 100/' .github/workflows/ci.yml
git add .github/workflows/ci.yml
git commit -m "test: verify coverage enforcement"
git push origin main

# Wait for run to fail
gh run watch
```

**Validation**:

```
Ask Claude:
"Show me why the latest CI run failed"

Expected: "Coverage below 100% threshold"
```

**Restore**:

```bash
# Restore correct threshold
sed -i '' 's/COVERAGE < 100/COVERAGE < 90/' .github/workflows/ci.yml
git add .github/workflows/ci.yml
git commit -m "fix: restore 90% coverage threshold"
git push origin main
```

**âœ… Success Criteria**:

- Run fails when coverage below threshold
- Error message clearly states coverage issue
- Subsequent run passes with correct threshold

---

### Task 8: Test Deployment Trigger

**Goal**: Verify deployment only triggers on main branch after all tests pass

**Test 1: Feature branch (should NOT deploy)**:

```bash
# Create feature branch
git checkout -b test/deployment
echo "// test" >> app/page.tsx
git add app/page.tsx
git commit -m "test: deployment trigger"
git push origin test/deployment
```

**Validation**:

```
Ask Claude:
"Did the latest CI run include a deployment step?"

Expected: No - feature branches don't deploy
```

**Test 2: Main branch (should deploy)**:

```bash
# Merge to main
git checkout main
git merge test/deployment
git push origin main
```

**Validation**:

```
Ask Claude:
"Show me the deployment status from the latest run"

Expected: Deployment triggered after all tests passed
```

**Using Vercel MCP**:

```
Ask Claude:
"Show me the latest Vercel deployment for daggergm"

Expected: New deployment in progress or completed
```

**âœ… Success Criteria**:

- Feature branches don't trigger deployment
- Main branch triggers deployment
- Deployment only happens if all tests pass
- Vercel shows new deployment

---

### Task 9: Test Supabase MCP Integration

**Goal**: Verify database access via MCP

**Test 1: List projects**:

```
Ask Claude:
"List my Supabase projects"

Expected: Shows DaggerGM project (test and/or prod)
```

**Test 2: Query database**:

```
Ask Claude:
"Execute this SQL query on the DaggerGM test database:
SELECT table_name FROM information_schema.tables
WHERE table_schema = 'public'"

Expected: Lists database tables
```

**Test 3: Check RLS policies**:

```
Ask Claude:
"Check which tables in DaggerGM database are missing RLS policies"

Expected: Lists tables and their RLS status
```

**âœ… Success Criteria**:

- Can list projects
- Can execute SQL queries
- Can check RLS policies
- Responses are accurate

---

### Task 10: Test GitHub MCP Integration

**Goal**: Verify full GitHub integration

**Test 1: List branches**:

```
Ask Claude:
"Show me all branches in the daggergm repository"

Expected: Lists main, dev, feature branches
```

**Test 2: Recent commits**:

```
Ask Claude:
"Show me the 5 most recent commits on main"

Expected: Recent commit history with messages
```

**Test 3: Workflow monitoring**:

```
Ask Claude:
"What's the status of the latest GitHub Actions workflow run?
Show me any failed jobs."

Expected: Current workflow status and details
```

**Test 4: Pull requests**:

```
Ask Claude:
"List all open pull requests for daggergm"

Expected: Open PRs or "No open PRs"
```

**âœ… Success Criteria**:

- All queries return accurate data
- Can monitor workflow runs in real-time
- Can access PR information
- Response time < 5 seconds

---

### Task 11: Test Vercel MCP Integration

**Goal**: Verify deployment management via MCP

**Test 1: List deployments**:

```
Ask Claude:
"Show me the 5 most recent Vercel deployments for daggergm"

Expected: Recent deployment history
```

**Test 2: Deployment status**:

```
Ask Claude:
"What's the status of the latest Vercel deployment?
Is it ready, building, or errored?"

Expected: Current deployment status
```

**Test 3: Deployment logs** (if available):

```
Ask Claude:
"Show me the build logs from the latest Vercel deployment"

Expected: Recent build logs
```

**âœ… Success Criteria**:

- Can list deployments
- Can check deployment status
- Can access logs
- Accurate real-time information

---

### Task 12: Performance Benchmarking

**Goal**: Document actual performance improvements

**Collect metrics**:

```bash
# Get last 10 workflow runs
gh run list --limit 10 --json durationMs,conclusion,displayTitle

# Calculate average duration
gh run list --limit 20 --json durationMs \
  | jq '[.[] | .durationMs] | add / length / 60000'

# Expected: ~20-22 minutes average
```

**Using MCP**:

```
Ask Claude:
"Show me the duration of the last 10 workflow runs.
What's the average duration?"

Expected: Average ~20-22 minutes
```

**Document results**:

```bash
cat >> documentation/CI_CD_PERFORMANCE.md << 'EOF'
# CI/CD Performance Metrics

## Baseline (Before Optimization)
- Full test suite: ~25 minutes
- Documentation changes: ~25 minutes (wasted)
- Flaky test failure rate: ~4%
- Monthly CI minutes: ~2,000

## After Optimization (Phase 1-3)
- Full test suite: ~20 minutes âœ…
- Documentation changes: 0 minutes (skipped) âœ…
- Flaky test success rate: 98%+ (with retry) âœ…
- Monthly CI minutes estimate: ~1,200

## Savings
- Time per full run: 20% faster
- Documentation skips: 100% saved
- Flaky test handling: 98%+ success rate
- **Total monthly savings: 40-50% CI minutes**

## Run Duration by Scenario
1. Documentation only: 0 min (skipped)
2. Lint fixes only: ~7 min (lint + build)
3. Code changes (no tests needed): ~12 min
4. Full test suite: ~20 min
5. With E2E tests: ~22 min

## Historical Data
EOF

# Append actual run data
gh run list --limit 20 --json number,displayTitle,conclusion,durationMs \
  | jq -r '.[] | "\(.number),\(.displayTitle),\(.conclusion),\(.durationMs/60000)"' \
  >> documentation/CI_CD_PERFORMANCE.md
```

**âœ… Success Criteria**:

- Full suite runs in ~20 minutes (vs 25 before)
- Documentation changes take 0 minutes (vs 25 before)
- 40-50% overall time savings achieved

---

### Task 13: Create Monitoring Dashboard

**Goal**: Document common monitoring commands

**Create file**: `documentation/CI_CD_MONITORING.md`

```markdown
# CI/CD Monitoring Guide

## Quick Status Checks

### Using GitHub MCP (Recommended)

\`\`\`
Claude Commands:
"What's the status of the latest CI run?"
"Show me failing tests from the latest run"
"List recent deployments"
"Monitor the current workflow and notify me when complete"
\`\`\`

### Using GitHub CLI

\`\`\`bash

# Current status

gh run list --limit 5

# Watch current run

gh run watch

# View logs

gh run view --log

# Failed jobs only

gh run view --log-failed
\`\`\`

## Performance Monitoring

### Average Duration

\`\`\`bash

# Last 20 runs average

gh run list --limit 20 --json durationMs \\
| jq '[.[] | .durationMs] | add / length / 60000'
\`\`\`

### Success Rate

\`\`\`bash

# Last 50 runs

gh run list --limit 50 --json conclusion \\
| jq '[.[] | select(.conclusion == "success")] | length'
\`\`\`

## Deployment Monitoring

### Using Vercel MCP

\`\`\`
Claude Commands:
"Show latest Vercel deployment status"
"What's the build time for recent deployments?"
"Show me deployment logs"
\`\`\`

### Using Vercel Dashboard

https://vercel.com/sagebright/daggergm/deployments

## Database Monitoring

### Using Supabase MCP

\`\`\`
Claude Commands:
"Show me tables in DaggerGM database"
"Execute: SELECT COUNT(\*) FROM adventures"
"Check RLS policy coverage"
\`\`\`

## Alert Thresholds

Set up alerts for:

- Run duration > 30 minutes (something is stuck)
- Success rate < 95% (flaky tests)
- Coverage < 90% (quality degradation)
- Deployment failures

## Troubleshooting

### Run taking too long

1. Check if tests are stuck (timeout should catch)
2. Check for database connection issues
3. Verify no infinite loops in tests

### Tests failing in CI but not locally

1. Check environment variables
2. Verify test database is accessible
3. Check timezone differences (CI uses UTC)
4. Review full logs: \`gh run view --log\`

### Deployment not triggering

1. Verify on main branch: \`git branch\`
2. Check all tests passed
3. Verify VERCEL_DEPLOY_HOOK_URL secret exists
4. Check Vercel dashboard for errors
   \`\`\`

---

**Last Updated**: 2025-10-23
**Tools**: GitHub MCP, Vercel MCP, GitHub CLI
```

---

### Task 14: Final Validation Report

**Create comprehensive validation report**:

```bash
# Generate report
cat > documentation/PHASE_3_VALIDATION_REPORT.md << 'EOF'
# Phase 3 Validation Report

**Date**: $(date +%Y-%m-%d)
**Duration**: 45 minutes
**Status**: âœ… Complete

## Test Results

### Scenario Testing
- [x] Documentation-only changes skip CI
- [x] `[skip ci]` flag works correctly
- [x] Lint-only changes complete quickly
- [x] Full test suite runs successfully
- [x] Auto-retry handles flaky tests
- [x] Coverage enforcement works
- [x] Deployment triggers only on main
- [x] Feature branches don't deploy

### MCP Integration Testing
- [x] Supabase MCP lists projects
- [x] Supabase MCP executes queries
- [x] GitHub MCP shows workflow status
- [x] GitHub MCP lists PRs and branches
- [x] Vercel MCP shows deployments
- [x] All MCP responses < 5 seconds

### Performance Metrics
- Baseline (before): ~25 min full suite
- Current (after): ~20 min full suite
- Improvement: 20% faster
- Doc skip savings: 100% (0 vs 25 min)
- **Total savings: 40-50% monthly**

## Issues Encountered

[Document any issues found and how they were resolved]

## Recommendations

1. Monitor coverage trends weekly
2. Review flaky tests that need retries
3. Rotate MCP tokens every 90 days
4. Set up Slack notifications for failures
5. Review CI costs monthly

## Next Steps

1. Phase 4: Database setup (separate doc)
2. Configure Slack notifications
3. Set up coverage trend tracking
4. Document team workflow

---

**Validated By**: Claude (Phase 3 execution)
**Sign-off**: All tests passing, MCP operational
EOF
```

---

## âœ… Final Checklist

Verify all components working:

- [ ] Documentation changes skip CI (0 min)
- [ ] `[skip ci]` flag respected
- [ ] Full test suite completes in ~20 min
- [ ] Auto-retry works for flaky tests
- [ ] Coverage threshold enforced (90%)
- [ ] TypeScript typecheck runs
- [ ] E2E tests run in parallel
- [ ] Deployment triggers only on main
- [ ] Feature branches don't deploy
- [ ] Supabase MCP queries database
- [ ] GitHub MCP monitors workflows
- [ ] Vercel MCP shows deployments
- [ ] Performance metrics documented
- [ ] Monitoring guide created
- [ ] Validation report completed

---

## ðŸ“Š Expected Final State

### Workflow Performance

| Scenario      | Duration   | vs Baseline |
| ------------- | ---------- | ----------- |
| Documentation | 0 min      | -100% âœ…    |
| Lint only     | ~7 min     | -72% âœ…     |
| Full suite    | ~20 min    | -20% âœ…     |
| Monthly total | ~1,200 min | -40% âœ…     |

### MCP Capabilities

- âœ… Database queries from Claude
- âœ… CI/CD monitoring from Claude
- âœ… Deployment management from Claude
- âœ… No CLI tools required

### Quality Standards

- âœ… 90% coverage enforced
- âœ… Zero tolerance (0 failures)
- âœ… TypeScript strict mode checked
- âœ… Auto-retry for flaky tests

---

## ðŸŽ‰ Success!

If all tasks complete successfully:

1. **Workflow optimized**: 40-50% cost reduction
2. **MCP integrated**: Full service access via Claude
3. **Quality maintained**: 90% coverage, zero tolerance
4. **Developer experience**: Faster feedback, better monitoring

**Ready for Phase 4**: Database setup and first integration test!

---

**Last Updated**: 2025-10-23
**Execution Time**: 30-45 minutes
**Difficulty**: Medium
**Prerequisites**: Phase 1 & 2 completed
